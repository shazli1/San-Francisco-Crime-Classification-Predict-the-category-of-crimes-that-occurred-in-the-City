# Project  Overview:

In this Project , you are required to use PySpark to predict what type of crime will occur in a given region 

https://www.kaggle.com/c/sf-crime/overview

From 1934 to 1963, San Francisco was infamous for housing some of the world's most notorious criminals on the inescapable island of Alcatraz.

Today, the city is known more for its tech scene than its criminal past. But, with rising wealth inequality, housing shortages, and a proliferation of expensive digital toys riding BART to work, there is no scarcity of crime in the city by the bay.

From Sunset to SOMA, and Marina to Excelsior, this competition's dataset provides nearly 12 years of crime reports from across all of San Francisco's neighborhoods. Given time and location, you must predict the category of crime that occurred.

We're also encouraging you to explore the dataset visually. What can we learn about the city through visualizations like this Top Crimes Map? The top most up-voted scripts from this competition will receive official Kaggle swag as prizes. 


You are not allowed to use Pandas except in aggregations and visualizations or for final submission , all other data wrangling and model training should be done using the Pyspark library . 


## Requirements:

1- A jupyter notebook detailing all your code in loading , cleaning  , analyzing , modeling and predictions 

2- At least 3 EDA steps  

3- Document using  at least 3 different models with 3 hyperparameters tuning per model and document the result of each one 

4- Document your best submission by a screenshot 

5- Try to explain why you think this particular model got the best result? 

6- Both jupyter and final document should be uploaded in a single zip file by one of the group members 
